{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Tue Jun 26 15:04:00 2018\\n\\n@author: i015225\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 22 10:12:35 2017\n",
    "TODO\n",
    "\n",
    "# For batch generator and multiproc c.f.\n",
    "    https://gist.github.com/tdeboissiere/195dde7fddfcf622a82a895b90d2c800\n",
    "# SEE ATHENA >> /examples/research/cbb_keras_tensorflow.py\n",
    "\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "# =============================================================================\n",
    "\n",
    "# see for GPU  https://keras.io/utils/#multi_gpu_model\n",
    "\n",
    "@author: i015225\n",
    "\"\"\"\n",
    "\n",
    "# In[Headless Server for faster img generation]\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# In[139]:\n",
    "#c=get_ipython()\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%pprint #Toggle\n",
    "# get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_bool_dtype, is_categorical, infer_dtype, is_categorical_dtype\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import AutoDateLocator, AutoDateFormatter, date2num\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# Import the scikit-learn function to confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Import the scikit-learn function to compute error.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "#import tensorflow as tf\n",
    "#import numpy\n",
    "from keras import layers, models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten, Embedding, TimeDistributed\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler ,quantile_transform\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras import callbacks\n",
    "\n",
    "import threading\n",
    "    \n",
    "# In[Charts]:\n",
    " # -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun 26 15:04:00 2018\n",
    "\n",
    "@author: i015225\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def img_gen_type(kind='scatter', n=5, grid=False, legend=False, xticks=False, yticks=False, border=False, draw_size=2.24, color=['black'], style=None, show=False):\n",
    "    \"\"\" Generate a random chart exporting height array and pixel array\n",
    "        use yticks=[] etc to hide. None to show default\n",
    "        TODO: Add options for randomising scale, # bars, showing axis, grids, rotating labels, legends etc.\n",
    "        TODO: drop Y-Axis labels\n",
    "        TODO: change background\n",
    "        TODO: axis ticks/label rotation\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(data=np.random.rand(n,1), index=range(1,n+1), columns=['y'])\n",
    "    #m,n = np.shape(data)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    if kind=='scatter':\n",
    "        # TODO add s for size and c for color per point , perhaps colormap='viridis'\n",
    "        data['x']= data.index\n",
    "        data.plot(ax=ax, kind=kind, x='x', y='y' , figsize=(draw_size, draw_size), grid=grid, legend=legend, style=style, color=color, marker='.', s=3)\n",
    "        data.drop(['x'], axis=1, inplace=True)\n",
    "    else:\n",
    "        data.plot(ax=ax, kind=kind , figsize=(draw_size, draw_size), grid=grid, legend=legend, style=style, color=color)\n",
    "\n",
    "    if not xticks:\n",
    "        x_axis = ax.axes.get_xaxis()\n",
    "        x_axis.set_visible(False)\n",
    "    if not yticks:\n",
    "        #ax1 = plt.axes()\n",
    "        y_axis = ax.axes.get_yaxis()\n",
    "        y_axis.set_visible(False)\n",
    "        \n",
    "    if not border:   \n",
    "        plt.axis('off') #https://stackoverflow.com/questions/40705614/hide-axis-label-only-not-entire-axis-in-pandas-plot\n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    # grab the pixel buffer and dump it into a numpy array\n",
    "    pixels = np.array(fig.canvas.renderer._renderer)[:,:,:3]/255\n",
    "    \n",
    "    if not show:\n",
    "        plt.close()\n",
    "    # print(pixels.shape)\n",
    "    return pixels, data.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Now make the data generator threadsafe ####################\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            return self.it.next()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def img_gen_safe(chttype='bar', batch = 10): #TODO add kwargs list\n",
    "    if chttype=='rand':\n",
    "        # use a random integer to choose the chart type\n",
    "        chttype = np.random.randint(0,3)\n",
    "        chttype = ['bar','plot','scatter'][chttype]  #,'histo'\n",
    "\n",
    "    while True:\n",
    "        X=[]\n",
    "        y=[]\n",
    "        for b in range(batch):\n",
    "            #do some drawing\n",
    "            X_, y_ = img_gen_type(kind=chttype)\n",
    "\n",
    "            X.append(X_)\n",
    "            y.append(y_.T)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.stack(y)\n",
    "\n",
    "        yield X, y\n",
    "    #return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_gen(chttype='bar', batch = 10): #TODO add kwargs list\n",
    "    if chttype=='rand':\n",
    "        # use a random integer to choose the chart type\n",
    "        chttype = np.random.randint(0,3)\n",
    "        chttype = ['bar','plot','scatter'][chttype]  #,'histo'\n",
    "\n",
    "    while True:\n",
    "        X=[]\n",
    "        y=[]\n",
    "        for b in range(batch):\n",
    "            #do some drawing\n",
    "            X_, y_ = img_gen_type(kind=chttype)\n",
    "\n",
    "            X.append(X_)\n",
    "            y.append(y_.T)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.stack(y)\n",
    "\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_generator( batch_size, shift_fraction=0.):\n",
    "    gen = img_gen(chttype='scatter', batch = 5)  #add arguments here for color='rand', chttype=... etc.\n",
    "    while True:\n",
    "        x_batch, y_batch = next(gen)\n",
    "        yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "    return ([x_batch, y_batch], [y_batch, x_batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = img_gen(chttype='scatter', batch = 5)  #add arguments here for color='rand', chttype=... etc.\n",
    "X,y = next(gen)#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26466733 0.69680911 0.74433061 0.77580667 0.06979797]\n",
      " [0.50128855 0.56583097 0.52116675 0.59887559 0.54529723]\n",
      " [0.5403671  0.48509047 0.75114016 0.04069109 0.62052449]\n",
      " [0.87449496 0.78116094 0.57559513 0.23030076 0.93131143]\n",
      " [0.94439522 0.40514459 0.33580496 0.55129404 0.41916742]]\n"
     ]
    }
   ],
   "source": [
    "#X,y=img_gen_type(kind='bar', show=True)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[Build Keras Model CNN]:\n",
    "def model_CNN(x_train, y_train, x_test=None, y_test=None, kwargs={}):\n",
    "    \"\"\" Build but do not run a NN model in Keras framework\n",
    "        train and test data requried to determine model types, dimensions etc.\n",
    "        x_train, y_train, x_test, y_test, kwargs = self.X4, self.y, None, None, self.kwargs\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Notes on Input shape\n",
    "    4D tensor with shape (batch_size, timesteps, features, `colors`).\n",
    "    4D tensor with shape: (samples, rows, cols, channels)\n",
    "    `channels_last` (default)\n",
    "    Output 4D tensor with shape: (samples, new_rows, new_cols, filters)\n",
    "    \"\"\"\n",
    "    ######## CNN for stocks\n",
    "    # create and fit CNN\n",
    "    # input_shape = StockDate x Lookback x Features\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "    layers = kwargs.get('layers', 10 ) #TODO\n",
    "    nodes = kwargs.get('nodes', None) #TODO\n",
    "\n",
    "    if nodes is None or nodes==0 or nodes==[0]:\n",
    "        nodes = [np.shape(x_train)[1]*3]\n",
    "    elif isinstance(nodes, (int, np.integer)): # turn int to list\n",
    "        nodes = [nodes]\n",
    "\n",
    "    if layers > 1 and len(nodes) < layers:\n",
    "        nodes = list(np.pad(nodes,[0,layers-len(nodes)], mode='constant',constant_values=nodes[-1]))\n",
    "\n",
    "    ndim = np.max([2,len(np.shape(x_train))]) # Min 2D\n",
    "    if ndim==2:\n",
    "        input_shape=(x_train.shape[1],)\n",
    "    elif ndim==3:\n",
    "        input_shape=(x_train.shape[1],x_train.shape[2])\n",
    "    elif ndim==4:\n",
    "        input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
    "    else:\n",
    "        input_shape=x_train.shape[1:]\n",
    "    if kwargs.get('learning_rate', False):\n",
    "        lr = kwargs.get('learning_rate')\n",
    "    else:\n",
    "        lr = False\n",
    "\n",
    "    if False:\n",
    "        conv = (3, 3)\n",
    "    else:\n",
    "        conv = (2, 2)\n",
    "        n_conv = 5\n",
    "\n",
    "    if np.ndim(y_train)==1:\n",
    "        n_out = 1 #e.g. forecast y as float, just 1 step ahead.\n",
    "    else:\n",
    "        n_out = np.shape(y_train)[1] #e.g. onehot encoded, or n-steps ahead.\n",
    "\n",
    "    dropout = kwargs.get('dropout',0) # dropout rate between 0 and 1.\n",
    "    #stateful = kwargs.get('stateful',True)\n",
    "    actvn = 'relu' #kwargs.get('actvn','relu')\n",
    "    actvl = kwargs.get('actvl','sigmoid')\n",
    "    model=[]\n",
    "    model = Sequential()  # https://keras.io/models/sequential/\n",
    "    model.reset_states()\n",
    "    # input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    model.add(Conv2D(n_conv, conv, activation=actvn, input_shape=input_shape))\n",
    "    #model.add(Conv2D(n_conv, conv, activation=actvn))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout ))\n",
    "\n",
    "    model.add(Conv2D(n_conv*2, conv, activation=actvn))\n",
    "    #model.add(Conv2D(n_conv*2, conv, activation=actvn))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(np.min(input_shape[1:-1]), activation=actvn))\n",
    "    model.add(Dropout(dropout*2))\n",
    "    model.add(Dense(n_out, activation=actvl))\n",
    "\n",
    "    if hasattr(kwargs,'optimizer'):\n",
    "        optimizer = kwargs['optimizer']\n",
    "    elif lr:\n",
    "        optimizer = SGD(lr=lr, decay=1e-6, momentum=0.01, nesterov=True)\n",
    "    else:\n",
    "        optimizer = 'Nadam' #keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "    if is_bool_dtype(y_train):\n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    if is_categorical_dtype(y_train) or kwargs.get('onehot',False):\n",
    "        #TODO Multiple Category\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    else:\n",
    "        #model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[r2_keras])\n",
    "\n",
    "\n",
    "    if kwargs.get('verbose',False) > 1:\n",
    "        model.summary()\n",
    "        print(\"Inputs: {}\".format(model.input_shape))\n",
    "        print(\"Outputs: {}\".format(model.output_shape))\n",
    "        print(\"Actual input: {}\".format(x_train.shape))\n",
    "        print(\"Actual output: {}\".format(y_train.shape))\n",
    "        print('Model Loss: ' + model.loss)\n",
    "\n",
    "    # For compatability with other models;\n",
    "    model.score = model.evaluate\n",
    "\n",
    "    return model #self.model=model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    # calculate R2 value (not built in :( )\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    #( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "    return ( 1 - SS_res/(SS_tot ) )\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[Setup Config Variables]\n",
    "verbose = 2  #True/False, extra verbose=2\n",
    "\n",
    "config={}\n",
    "#lagged return features\n",
    "config['verbose'] = 3  #Single Int\n",
    "#config['layers'] = 3  #Single Int\n",
    "#config['nodes'] = [300*200*10, 300*200*5, 300*200]#[75, 50, 25, 10, 5] #ignored for 1 layer. size of output. None to match X[0], Int or list of dims per layer. [10, 5, 1]\n",
    "#config['epochs'] = 10  # e.g. use 3*3 for 1st tstrain then 3 for tsroll (lower 'weight'? if less epochs)\n",
    "#config['actvn'] = 'relu' #tanh'  #\n",
    "\n",
    "config['Description'] = 'Digitize Bar Charts'\n",
    "config['StartTime'] = time.time()\n",
    "\n",
    "config['Model'] = \"CNN\"\n",
    "config['iterations'] = 1000  #Single Int\n",
    "\n",
    "\n",
    "class_names = ['False','True']  # Corresponds to False, True\n",
    "\n",
    "\n",
    "# In[Setup args]:\n",
    "class my_args():\n",
    "    def __init__(self):\n",
    "        self.lr = 0.01\n",
    "        self.lr_decay  = 0.001\n",
    "        self.lam_recon = 0.392  # , type=float,           help=\"The coefficient for the loss of decoder\")\n",
    "        self.routings = 3\n",
    "        #return self\n",
    "args = my_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 5)       65        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 5)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 111, 111, 5)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 10)      210       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 55, 55, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 55, 55, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30250)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 224)               6776224   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1125      \n",
      "=================================================================\n",
      "Total params: 6,777,624\n",
      "Trainable params: 6,777,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Inputs: (None, 224, 224, 3)\n",
      "Outputs: (None, 5)\n",
      "Actual input: (500, 224, 224, 3)\n",
      "Actual output: (500, 5)\n",
      "Model Loss: mean_squared_error\n",
      "Shapes of 1st Training sets:  (500, 224, 224, 3) (500, 5)\n"
     ]
    }
   ],
   "source": [
    "# In[Build Keras Model ]:\n",
    "if True:\n",
    "    # Setup image generator\n",
    "    gen = img_gen(chttype='scatter', batch = 500)  #add arguments here for color='rand', chttype=... etc.\n",
    "\n",
    "    # Create sample data\n",
    "    X, y = next(gen) #next is default\n",
    "\n",
    "    # Build model\n",
    "    model = model_CNN(X, y, x_test=None, y_test=None, kwargs=config)\n",
    "    # Then produce evaluation data set or 1 off dataset\n",
    "\n",
    "    print(\"Shapes of 1st Training sets: \", np.shape(X), np.shape(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Fit and Predicting for img. Shapes:  (500, 224, 224, 3) (500, 5)\n",
      "Epoch 1/11\n",
      "10/10 [==============================] - 263s 26s/step - loss: 0.0845 - r2_keras: -0.0216\n",
      "Epoch 2/11\n",
      "10/10 [==============================] - 259s 26s/step - loss: 0.0805 - r2_keras: 0.0361\n",
      "Epoch 3/11\n",
      "10/10 [==============================] - 252s 25s/step - loss: 0.0840 - r2_keras: -0.0140\n",
      "Epoch 4/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0840 - r2_keras: -0.0011\n",
      "Epoch 5/11\n",
      "10/10 [==============================] - 254s 25s/step - loss: 0.1054 - r2_keras: -0.2603\n",
      "Epoch 6/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0797 - r2_keras: 0.0383\n",
      "Epoch 7/11\n",
      "10/10 [==============================] - 252s 25s/step - loss: 0.0835 - r2_keras: -0.0012\n",
      "Epoch 8/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0847 - r2_keras: -0.0010\n",
      "Epoch 9/11\n",
      "10/10 [==============================] - 254s 25s/step - loss: 0.0846 - r2_keras: -4.6141e-04\n",
      "Epoch 10/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0826 - r2_keras: -3.4193e-04\n",
      "Epoch 11/11\n",
      "10/10 [==============================] - 254s 25s/step - loss: 0.0841 - r2_keras: -3.8830e-04\n",
      "Training: Fit and Predicting for img. Shapes:  (500, 224, 224, 3) (500, 5)\n",
      "Epoch 1/11\n",
      "10/10 [==============================] - 263s 26s/step - loss: 0.0834 - r2_keras: -3.4207e-04\n",
      "Epoch 2/11\n",
      "10/10 [==============================] - 253s 25s/step - loss: 0.0830 - r2_keras: -5.8193e-04\n",
      "Epoch 3/11\n",
      "10/10 [==============================] - 250s 25s/step - loss: 0.0831 - r2_keras: -6.3850e-04\n",
      "Epoch 4/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0839 - r2_keras: -6.1179e-04\n",
      "Epoch 5/11\n",
      "10/10 [==============================] - 253s 25s/step - loss: 0.0830 - r2_keras: -9.3120e-04\n",
      "Epoch 6/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0834 - r2_keras: -7.9325e-04\n",
      "Epoch 7/11\n",
      "10/10 [==============================] - 255s 26s/step - loss: 0.0839 - r2_keras: -0.0011\n",
      "Epoch 8/11\n",
      "10/10 [==============================] - 254s 25s/step - loss: 0.0832 - r2_keras: -5.4756e-04\n",
      "Epoch 9/11\n",
      "10/10 [==============================] - 254s 25s/step - loss: 0.0839 - r2_keras: -4.2102e-04\n",
      "Epoch 10/11\n",
      "10/10 [==============================] - 252s 25s/step - loss: 0.0830 - r2_keras: -6.6600e-04\n",
      "Epoch 11/11\n",
      "10/10 [==============================] - 255s 25s/step - loss: 0.0826 - r2_keras: -9.0739e-04\n",
      "Training: Fit and Predicting for img. Shapes:  (500, 224, 224, 3) (500, 5)\n",
      "Epoch 1/11\n",
      "10/10 [==============================] - 261s 26s/step - loss: 0.0828 - r2_keras: -7.6458e-04\n",
      "Epoch 2/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0839 - r2_keras: -7.3072e-04\n",
      "Epoch 3/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0837 - r2_keras: -0.0010\n",
      "Epoch 4/11\n",
      "10/10 [==============================] - 255s 25s/step - loss: 0.0842 - r2_keras: -3.9394e-04\n",
      "Epoch 5/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0831 - r2_keras: -0.0013\n",
      "Epoch 6/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0835 - r2_keras: -4.9385e-04\n",
      "Epoch 7/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0835 - r2_keras: -5.8339e-04\n",
      "Epoch 8/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0838 - r2_keras: -7.1135e-04\n",
      "Epoch 9/11\n",
      "10/10 [==============================] - 267s 27s/step - loss: 0.0828 - r2_keras: -4.6849e-04\n",
      "Epoch 10/11\n",
      "10/10 [==============================] - 268s 27s/step - loss: 0.0835 - r2_keras: -0.0010\n",
      "Epoch 11/11\n",
      "10/10 [==============================] - 265s 27s/step - loss: 0.0827 - r2_keras: -0.0012\n",
      "Training: Fit and Predicting for img. Shapes:  (500, 224, 224, 3) (500, 5)\n",
      "Epoch 1/11\n",
      "10/10 [==============================] - 261s 26s/step - loss: 0.0823 - r2_keras: -9.9384e-04\n",
      "Epoch 2/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0836 - r2_keras: -7.7822e-04\n",
      "Epoch 3/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0842 - r2_keras: -5.1456e-04\n",
      "Epoch 4/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0837 - r2_keras: -0.0015\n",
      "Epoch 5/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0838 - r2_keras: -9.2971e-04\n",
      "Epoch 6/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0835 - r2_keras: -7.9279e-04\n",
      "Epoch 7/11\n",
      "10/10 [==============================] - 255s 26s/step - loss: 0.0836 - r2_keras: -6.6279e-04\n",
      "Epoch 8/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0828 - r2_keras: -5.4280e-04\n",
      "Epoch 9/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0839 - r2_keras: -4.4177e-04\n",
      "Epoch 10/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0832 - r2_keras: -8.3572e-04\n",
      "Epoch 11/11\n",
      "10/10 [==============================] - 259s 26s/step - loss: 0.0839 - r2_keras: -6.5525e-04\n",
      "Training: Fit and Predicting for img. Shapes:  (500, 224, 224, 3) (500, 5)\n",
      "Epoch 1/11\n",
      "10/10 [==============================] - 260s 26s/step - loss: 0.0835 - r2_keras: -3.2661e-04\n",
      "Epoch 2/11\n",
      "10/10 [==============================] - 259s 26s/step - loss: 0.0827 - r2_keras: -8.9255e-04\n",
      "Epoch 3/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0829 - r2_keras: -4.2714e-04\n",
      "Epoch 4/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0835 - r2_keras: -7.8279e-04\n",
      "Epoch 5/11\n",
      "10/10 [==============================] - 260s 26s/step - loss: 0.0826 - r2_keras: -0.0014\n",
      "Epoch 6/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0834 - r2_keras: -7.6695e-04\n",
      "Epoch 7/11\n",
      "10/10 [==============================] - 254s 25s/step - loss: 0.0843 - r2_keras: -5.7476e-04\n",
      "Epoch 8/11\n",
      "10/10 [==============================] - 258s 26s/step - loss: 0.0833 - r2_keras: -8.9026e-04\n",
      "Epoch 9/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0824 - r2_keras: -0.0010\n",
      "Epoch 10/11\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.0834 - r2_keras: -6.0545e-04\n",
      "Epoch 11/11\n",
      "10/10 [==============================] - 257s 26s/step - loss: 0.0830 - r2_keras: -5.4428e-04\n",
      "Training: Fit and Predicting for img. Shapes:  (500, 224, 224, 3) (500, 5)\n",
      "Epoch 1/11\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Your generator is NOT thread-safe.Keras requires a thread-safe generator when`use_multiprocessing=False, workers > 1`.For more information see issue #1638.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: generator already executing",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6583c11e1b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# Step 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mmdlfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, steps=100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'generator already executing'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 raise RuntimeError(\n\u001b[0;32m--> 705\u001b[0;31m                     \u001b[0;34m\"Your generator is NOT thread-safe.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m                     \u001b[0;34m\"Keras requires a thread-safe generator when\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Your generator is NOT thread-safe.Keras requires a thread-safe generator when`use_multiprocessing=False, workers > 1`.For more information see issue #1638."
     ]
    }
   ],
   "source": [
    "\n",
    "# In[Evaluate/Test Keras Simple]:\n",
    "if True:\n",
    "    if True:\n",
    "        #model.evaluate(x_train_k, y_train_k, batch_size=1, verbose=1)\n",
    "        mdlfit=[]\n",
    "        mdlscr=[]\n",
    "        mdlprd=[]\n",
    "\n",
    "        # Make predictions.\n",
    "        if True: #Use safe generator\n",
    "            #gen is unsafe...?\n",
    "            safe_gen = img_gen(chttype='scatter', batch = 500)  #add arguments here for color='rand', chttype=... etc.\n",
    "            spare_gen = img_gen(chttype='scatter', batch = 50)\n",
    "            third_gen = img_gen(chttype='scatter', batch = 50)\n",
    "            \n",
    "            i = 0\n",
    "            while i < config.get('iterations', 3):\n",
    "                i += 1\n",
    "                #X, y = next(gen)\n",
    "                if verbose: print('Training: Fit and Predicting for %s. Shapes: '%('img'), np.shape(X), np.shape(y))\n",
    "\n",
    "                # Step 1\n",
    "                m = model.fit_generator(safe_gen, steps_per_epoch=10, verbose=1, epochs=11)\n",
    "                mdlfit.append(m) #, steps=100))\n",
    "\n",
    "                # evaluate the model\n",
    "                s = model.evaluate_generator(spare_gen, steps=10)\n",
    "                mdlscr.append(s)\n",
    "                #if verbose>1:print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[-1]*100))\n",
    "\n",
    "            # Finished let's see\n",
    "            #X_test,  y_test  = next(gen)\n",
    "\n",
    "            #mdlprd = model.predict(X_test)   #, index=X.loc[x_train.index[L:]].index)\n",
    "            mdlprd = model.predict_generator(generator=third_gen)\n",
    "        else: # Single estimate\n",
    "            X_train,  y_train  = next(gen)\n",
    "            X_test,  y_test  = next(gen)\n",
    "            mdlfit = model.fit(X_train, y_train, epochs=config.get('epochs'), batch_size=1, verbose=1, shuffle=False) #y.astype(int)\n",
    "            mdlprd = model.predict(X_test)   #, index=X.loc[x_train.index[L:]].index)\n",
    "            mdlscr = model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/mesos/sandbox/data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## In[Save Keras Model]:\n",
    "\n",
    "hist = pd.DataFrame([m.history['loss']  for m in mdlfit],columns=['loss'])\n",
    "hist['oos'] = np.array(mdlscr)[:,0]\n",
    "print('training loss',hist)\n",
    "print('oos loss')\n",
    "hist.plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
